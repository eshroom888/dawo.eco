# Epic 2 Retrospective: Research Intelligence Pipeline

**Date:** 2026-02-07
**Facilitator:** Bob (Scrum Master)
**Epic Status:** Complete (8/8 stories)

---

## Epic Summary

| Metric | Value |
|--------|-------|
| Stories Completed | 8/8 (100%) |
| Total Tests Created | 1,273 |
| Pipeline Pattern | Harvester Framework |
| Scanners Built | 5 (Reddit, YouTube, Instagram, News, PubMed) |
| FRs Covered | FR1-FR8 |

### Stories Delivered

1. **2-1: Research Pool Database & Storage** - PostgreSQL schema, ResearchPoolRepository, 77 tests
2. **2-2: Research Item Scoring Engine** - Composite scoring (5 components), 486 tests
3. **2-3: Reddit Research Scanner** - First scanner, established Harvester Framework, 102 tests
4. **2-4: YouTube Research Scanner** - First LLM-enhanced scanner (KeyInsightExtractor), 130 tests
5. **2-5: Instagram Trend Scanner** - Two-stage LLM (ThemeExtractor + HealthClaimDetector), CleanMarket integration, 134 tests
6. **2-6: Industry News Scanner** - Fully rule-based (NO LLM), RSS/Atom feeds, 107 tests
7. **2-7: PubMed Scientific Research Scanner** - Biopython Entrez, FindingSummarizer + ClaimValidator, 194 tests
8. **2-8: Research Compliance Validation** - Shared ResearchComplianceValidator bridging EU Compliance to scanners, 43 tests

---

## Epic 1 Action Item Follow-Through

| Action Item | Status | Evidence |
|-------------|--------|----------|
| Use `tier="scan\|generate\|strategize"` - NEVER model names | FOLLOWED | All scanners use tier="scan", LLM-enhanced stages use tier="generate" |
| Every new module gets `__all__` exports | FOLLOWED | Verified in story completion notes |
| Add logging to exception handlers | IMPROVED | Structured logging patterns documented |
| Extract magic numbers to constants | FOLLOWED | Configuration-driven approach across all stories |

---

## What Went Well

### Harvester Framework Pattern
- Established in Story 2.3 (Reddit Scanner), became the template for all subsequent scanners
- Pipeline stages: Scanner -> Harvester -> Transformer -> Validator -> Scorer -> Publisher -> Research Pool
- Each scanner followed the pattern with source-specific customizations
- Pattern accelerated development velocity - later scanners implemented faster

### LLM Tier Discipline
- Strict adherence to tier="scan" for scanning operations (Haiku)
- tier="generate" used appropriately for insight extraction and summarization (Sonnet)
- News Scanner (2.6) proved rule-based approach when LLM not needed - cost optimization
- No model name leaks throughout the epic

### Test Coverage Excellence
- 1,273 total tests across 8 stories
- Scoring Engine (2.2) had 486 tests covering all permutations
- Mock strategy refinements: external APIs, LLM responses, repository operations
- Integration tests with controlled fixtures caught issues unit tests missed

### Architectural Patterns Established
- **Dependency Injection** - All components receive dependencies via constructors
- **Scientific Citation Detection** - DOI/PMID patterns for trust signals (2.7)
- **Two-Stage LLM Chaining** - ThemeExtractor -> HealthClaimDetector pattern (2.5)
- **Shared Validators** - ResearchComplianceValidator bridges Epic 1's EU Compliance to all scanners

### Reuse of Epic 1 Components
- EU Compliance Checker integrated seamlessly into research validation
- LLM Tier Configuration used consistently
- Retry Middleware wrapped all external API calls
- Foundation-first strategy validated

---

## What We Struggled With

### Multi-Stage LLM Orchestration
- Instagram Scanner (2.5) required two sequential LLM calls
- Maintaining state consistency between ThemeExtractor and HealthClaimDetector
- Mock setup for testing chained LLM calls required new patterns

### Test Organization at Scale
- 1,273 tests required thoughtful organization
- Test discovery performance needed attention
- Refactored test structure mid-epic to maintain clarity

### Story Sizing Accuracy
- News Scanner (2.6) simpler than estimated (rule-based, no LLM)
- Non-LLM stories may be over-estimated in planning

### CleanMarket Integration Complexity
- Instagram Scanner needed to flag competitor content for violation review
- Cross-epic integration point added unexpected scope

---

## Key Insights

| # | Insight | Application |
|---|---------|-------------|
| 1 | Harvester Framework pattern = development velocity | Template-based approach accelerates similar work |
| 2 | LLM tier discipline prevents cost creep | Strict tier enforcement across all components |
| 3 | Scientific citations need special handling | DOI/PMID detection as trust signal pattern |
| 4 | Rule-based when possible | News Scanner proved LLM isn't always necessary |
| 5 | Shared validators compound value | One validator serves all scanners |
| 6 | Foundation-first pays dividends | Epic 1 components seamlessly integrated |
| 7 | Test count correlates with complexity | Scoring Engine (486) vs Compliance Validator (43) |

---

## Action Items

### Process Improvements

| Action | Owner | Deadline | Success Criteria |
|--------|-------|----------|------------------|
| Create LLM-chaining pattern documentation | Charlie | Before Epic 3 | Doc in project-context.md or patterns folder |
| Establish mock factory convention for multi-LLM tests | Elena | Before Story 3.3 | Template available for caption generation tests |
| Review story sizing for rule-based work | Alice | Sprint planning | Non-LLM stories sized appropriately |
| Define integration test organization standard | Dana | Before Epic 3 | Test structure documented, discovery fast |

### Team Agreements

- [ ] LLM-chaining follows ThemeExtractor -> HealthClaimDetector pattern from 2.5
- [ ] Rule-based processing preferred when pattern matching sufficient
- [ ] Scientific citation patterns (DOI, PMID, URLs) reused from 2.7
- [ ] Shared validators registered in team_spec.py with clear capability names

---

## Epic 3 Preparation

### Dependencies Ready (from Epic 1 & 2)

- EU Compliance Checker - Content validation (FR13)
- Brand Voice Validator - Norwegian caption checking (FR9, FR49)
- LLM Tier Config - Generators will use tier="generate" (Sonnet)
- Retry Middleware - Orshot, Shopify, Google Drive API calls
- Research Pool - Content source for caption generation
- Scoring Engine - Patterns applicable to Content Quality Scoring (3.7)

### Patterns to Carry Forward

- Dependency injection for all components
- Mock factory approach for complex test scenarios
- LLM-chaining for multi-stage generation
- Tier discipline (generate for quality content)

### Preparation Needed

- [ ] Orshot API credentials and template import from Canva
- [ ] Nano Banana (Gemini) API setup
- [ ] Google Drive folder structure creation
- [ ] Shopify MCP configuration
- [ ] Norwegian brand voice examples for caption generator

### Anticipated Complexity

- **Story 3.7 (Content Quality Scoring)** - 6 weighted components, expect 400+ tests
- **Story 3.3 (Instagram Caption Generator)** - Norwegian language, brand voice integration
- **Story 3.4 (Orshot Integration)** - External API with Canva template import

---

## No Significant Discoveries

Epic 2 execution validated our pipeline architecture. The Harvester Framework pattern proved robust across 5 diverse data sources. No changes needed to Epic 3 plan beyond preparation tasks.

---

## Next Steps

1. Complete preparation tasks (API credentials, folder structure)
2. Review action items in next standup
3. Begin Epic 3 with Story 3.1: Shopify Product Data Integration

---

## Retrospective Participants

- Alice (Product Owner)
- Bob (Scrum Master) - Facilitator
- Charlie (Senior Dev)
- Dana (QA Engineer)
- Elena (Junior Dev)
- eshroom (Project Lead)

---

*Generated by BMAD Retrospective Workflow*
